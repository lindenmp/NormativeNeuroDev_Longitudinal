#!/usr/bin/env python
# coding: utf-8

# # Preamble

# In[1]:


import os, sys, glob
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


# In[2]:


sys.path.append('/Users/lindenmp/Dropbox/Work/ResProjects/NormativeNeuroDev_Longitudinal/code/func/')
from proj_environment import set_proj_env
from func import get_cmap


# In[3]:


exclude_str = 't1Exclude' # 't1Exclude' 'fsFinalExclude'
parc_str = 'schaefer' # 'lausanne' 'schaefer'
parc_scale = 400
_ = set_proj_env(exclude_str = exclude_str, parc_str = parc_str, parc_scale = parc_scale)


# ### Setup output directory

# In[4]:


print(os.environ['BASEDIR'])
if not os.path.exists(os.environ['BASEDIR']): os.makedirs(os.environ['BASEDIR'])


# # Load in metadata

# In[5]:


# Protocol
prot = pd.read_csv(os.path.join(os.environ['DERIVSDIR'], 'pncDataFreeze20170905/n2416_dataFreeze/neuroimaging/n2416_pnc_protocol_validation_params_status_20170103.csv'))
# T1 QA
t1_qa = pd.read_csv(os.path.join(os.environ['DERIVSDIR'], 'pncDataFreeze20170905/n2416_dataFreeze/neuroimaging/t1struct/n2416_t1QaData_20170516.csv'))
# DTI QA
dti_qa = pd.read_csv(os.path.join(os.environ['DERIVSDIR'], 'pncDataFreeze20170905/n2416_dataFreeze/neuroimaging/dti/n2416_DTI64/n2416_dti_qa_20170301.csv'))
# REST QA
rest_qa = pd.read_csv(os.path.join(os.environ['DERIVSDIR'], 'pncDataFreeze20170905/n2416_dataFreeze/neuroimaging/rest/n2416_RestQAData_20170714.csv'))
# Demographics
demog = pd.read_csv(os.path.join(os.environ['DERIVSDIR'], 'pncDataFreeze20170905/n2416_dataFreeze/clinical/n2416_demographics_20170310.csv'))
# Brain volume
brain_vol = pd.read_csv(os.path.join(os.environ['DERIVSDIR'], 'pncDataFreeze20170905/n2416_dataFreeze/neuroimaging/t1struct/n2416_antsCtVol_20170412.csv'))
# incidental findings
inc_find = pd.read_csv(os.path.join(os.environ['DERIVSDIR'], 'pncDataFreeze20170905/n9498_dataFreeze/health/n9498_health_20170405.csv'))

# GOASSESS Bifactor scores
goassess = pd.read_csv('/Users/lindenmp/Dropbox/Work/ResData/PNC/GO_Longitudinal_clinical_factor_scores_psychosis_split_BIFACTOR.csv')
goassess.set_index(['bblid'], inplace = True)

# merge
df = prot
df = pd.merge(df, t1_qa, on=['scanid', 'bblid']) # t1_qa
df = pd.merge(df, dti_qa, on=['scanid', 'bblid']) # dti_qa
df = pd.merge(df, rest_qa, on=['scanid', 'bblid']) # rest_qa
df = pd.merge(df, demog, on=['scanid', 'bblid']) # demog
df = pd.merge(df, brain_vol, on=['scanid', 'bblid']) # brain_vol

print(df.shape[0])
df.set_index(['bblid', 'scanid'], inplace = True)
df = df.sort_index(axis = 0, level = 0)


# In[6]:


df['scanageYears'] = np.round(df.scanageMonths/12, decimals=1)


# In[7]:


df_tmp = pd.merge(df, inc_find, on=['bblid']) # goassess


# In[8]:


df.loc[:,'incidentalFindingExclude'] = df_tmp.loc[:,'incidentalFindingExclude'].copy().values


# # Filter subjects

# Filter out subjects using the QA procedures generated by BBL.

# In[9]:


# 0) incidental findings
df = df[df['incidentalFindingExclude'] == 0]
print('N after incidentalFindingExclude:', df.shape[0])

# 2) T1 exclusion
df = df[df[exclude_str] == 0]
df = df[df['t1PostProcessExclude'] == 0]
print('N after T1 exclusion:', df.shape[0])


# ### Missing imaging data

# ### Thickness

# Check if every participant actually has a cortical thickness data file. If not, exclude.

# In[10]:


subj_filt = np.zeros((df.shape[0],)).astype(bool)

for (i, (index, row)) in enumerate(df.iterrows()):
    if parc_str == 'schaefer':
        full_path = glob.glob(os.path.join(os.environ['CTDIR'], str(index[0]), '*' + str(index[1]), os.environ['CT_FILE_NAME']))
        if len(full_path) == 0:
            subj_filt[i] = True

subj_filt.sum()


# In[11]:


df = df[~subj_filt]


# In[12]:


print('N after excluding missing subjects:', df.shape[0])


# ### Multiple scans

# Screen out people who, due to the QA screening above, have non-continuous scans. For example, if an individual's T2 scan doesn't pass QA, but T1 and T3 do.
# 
# Also, I retain those participants who have only single timepoints of data even if those timepoints aren't T1.

# In[13]:


keep_me = ([1],[2],[3],[1,2],[1,2,3])
idx_keep = []
idx_drop = []
for idx, data in df.groupby('bblid'):
    my_list = list(data['timepoint'].values)
    if my_list == keep_me[0] or my_list == keep_me[1] or my_list == keep_me[2] or my_list == keep_me[3] or my_list == keep_me[4]:
        idx_keep.append(idx)
    else:
        idx_drop.append(idx)


# In[14]:


df = df.loc[idx_keep,:]


# In[15]:


print('N after exclusion non-continuous scans:', df.shape[0])


# ### Create new total time points column

# The above filtering steps creates a mismatch between the number of timepoints each participant has according to BBL recruitment and how many I retain for analysis.
# 
# I create a new variable that counts the number of timpeoints each participant has after my filtering.

# In[16]:


for idx, data in df.groupby('bblid'):
    df.loc[idx,'TotalNtimepoints_new'] = int(data.shape[0])
df.loc[:,'TotalNtimepoints_new'] = df.loc[:,'TotalNtimepoints_new'].astype(int)


# In[17]:


print('N w/ 1 timepoint:', df.loc[df['TotalNtimepoints_new'] == 1,:].shape[0])
print('N w/ >=2 timepoints:', int(df.loc[df['TotalNtimepoints_new'] == 2,:].shape[0]/2 + df.loc[df['TotalNtimepoints_new'] == 3,:].shape[0]/3))
print('N w/ 3 timepoints:', int(df.loc[df['TotalNtimepoints_new'] == 3,:].shape[0]/3))


# ### Concat clinical data

# Note, this will fill missing phenotype data with NaNs. I prioritise retaining the full imaging sample for now.

# In[18]:


df.reset_index(inplace = True)
df.set_index(['bblid', 'timepoint'], inplace = True)
goassess.reset_index(inplace = True)
goassess.set_index(['bblid', 'timepoint'], inplace = True)


# In[19]:


goassess.loc[:,'scanid'] = np.float('nan')


# In[20]:


for idx, data in df.iterrows():
    goassess.loc[idx,'scanid'] = data['scanid']


# In[21]:


df_out = pd.merge(df, goassess, on=['bblid', 'scanid', 'timepoint']).reset_index()
df_out.set_index(['bblid', 'scanid', 'timepoint'], inplace = True)


# In[22]:


header = ['TotalNtimepoints', 'TotalNtimepoints_new', 'sex', 'race', 'ethnicity', 'scanageMonths', 'scanageYears', 'mprage_antsCT_vol_TBV', 'averageManualRating', 'dti32MeanRelRMS', 
          'Overall_Psychopathology', 'Mania', 'Depression', 'Psychosis_Positive', 'Psychosis_NegativeDisorg',]
df_out = df_out.loc[:,header]


# Designate the individuals with only 1 timepoint as 'train' (False) and individuals with longitudinal data as 'test' (True)

# In[23]:


df_out.loc[:,'train_test'] = df_out.loc[:,'TotalNtimepoints_new'] != 1


# In[24]:


df_out.head()


# ### Final numbers

# In[25]:


print('N w/ 1 timepoint:', df.loc[df['TotalNtimepoints_new'] == 1,:].shape[0])
print('N w/ >=2 timepoints:', int(df.loc[df['TotalNtimepoints_new'] == 2,:].shape[0]/2 + df.loc[df['TotalNtimepoints_new'] == 3,:].shape[0]/3))
print('N w/ 3 timepoints:', int(df.loc[df['TotalNtimepoints_new'] == 3,:].shape[0]/3))


# In[26]:


# find unique ages
age_unique = np.unique(df_out['scanageYears'])
print('There are', age_unique.shape[0], 'unique age points')

# Check if train and test represent the full unique age space
train_diff = np.setdiff1d(df_out.loc[~df_out.loc[:,'train_test'],'scanageYears'],age_unique)
test_diff = np.setdiff1d(df_out.loc[df_out.loc[:,'train_test'],'scanageYears'],age_unique)

if train_diff.size == 0:
    print('All unique age points are represented in the training set')
elif train_diff.size != 0:
    print('All unique age points ARE NOT represented in the training set')
    
if test_diff.size == 0:
    print('All unique age points are represented in the testing set')
elif test_diff.size != 0:
    print('All unique age points ARE NOT represented in the testing set')


# # Plots

# In[27]:


labels = ['Train', 'Test']
if not os.path.exists(os.environ['FIGDIR']): os.makedirs(os.environ['FIGDIR'])
os.chdir(os.environ['FIGDIR'])
sns.set(style='white', context = 'paper', font_scale = 1)
cmap = get_cmap('pair')

phenos = ('Overall_Psychopathology','Psychosis_Positive','Psychosis_NegativeDisorg','AnxiousMisery','Externalizing','Fear')
phenos_label_short = ('Ov. Psych.', 'Psy. (pos.)', 'Psy. (neg.)', 'Anx.-mis.', 'Ext.', 'Fear')
phenos_label = ('Overall Psychopathology','Psychosis (Positive)','Psychosis (Negative)','Anxious-Misery','Externalizing','Fear')
metrics = ('ct', 'str', 'ac', 'mc')
metrics_label_short = ('Thickness', 'Strength', 'Ave. ctrb.', 'Mod. ctrb.')
metrics_label = ('Thickness', 'Strength', 'Average controllability', 'Modal controllability')


# ## Age

# In[28]:


df_out.loc[:,'race'].unique()


# Predictably the test set has more data in the upper tail of the age distribution. This is because I define the test set based on individuals with multiple time points. This will limit the capacity for the normative model to generate deviations in the upper age range.

# In[29]:


f, axes = plt.subplots(1,3)
f.set_figwidth(8)
f.set_figheight(3)
colormap = sns.color_palette("pastel", 2)

sns.distplot(df_out.loc[~df_out.loc[:,'train_test'],'scanageYears'], bins=20, hist=True, kde=False, rug=False, label = labels[0],
             hist_kws={"histtype": "step", "linewidth": 2, "alpha": 1}, color=list(cmap[0]), ax = axes[0]);
sns.distplot(df_out.loc[df_out.loc[:,'train_test'],'scanageYears'], bins=20, hist=True, kde=False, rug=False, label = labels[1],
             hist_kws={"histtype": "step", "linewidth": 2, "alpha": 1}, color=list(cmap[1]), ax = axes[0]);
axes[0].legend(prop={'size': 8});
axes[0].set_xlabel('Age (years)');
axes[0].set_ylabel('Number of participants');
axes[0].set_xticks(np.arange(np.min(np.round(age_unique,0)), np.max(np.round(age_unique,0)), 2))

# set width of bar
barWidth = 0.25

# Sex
y_train = [np.sum(df_out.loc[~df_out.loc[:,'train_test'],'sex'] == 1), np.sum(df_out.loc[~df_out.loc[:,'train_test'],'sex'] == 2)]
y_test = [np.sum(df_out.loc[df_out.loc[:,'train_test'],'sex'] == 1), np.sum(df_out.loc[df_out.loc[:,'train_test'],'sex'] == 2)]
r1 = np.arange(len(y_train))+barWidth/2
r2 = [x + barWidth for x in r1]
axes[1].bar(r1, y_train, width = barWidth, color = cmap[0], label = labels[0])
axes[1].bar(r2, y_test, width = barWidth, color = cmap[1], label = labels[1])
axes[1].set_xlabel('Sex')
axes[1].set_xticks([r + barWidth for r in range(len(y_train))])
axes[1].set_xticklabels(['Male', 'Female'])

# Race
y_train = [np.sum(df_out.loc[~df_out.loc[:,'train_test'],'race'] == 1), np.sum(df_out.loc[~df_out.loc[:,'train_test'],'race'] == 2), np.sum(df_out.loc[~df_out.loc[:,'train_test'],'race'] > 2)]
y_test = [np.sum(df_out.loc[df_out.loc[:,'train_test'],'race'] == 1), np.sum(df_out.loc[df_out.loc[:,'train_test'],'race'] == 2), np.sum(df_out.loc[df_out.loc[:,'train_test'],'race'] > 2)]
# Set position of bar on X axis
r1 = np.arange(len(y_train))+barWidth/2
r2 = [x + barWidth for x in r1]

axes[2].bar(r1, y_train, width = barWidth, color = cmap[0], label = labels[0])
axes[2].bar(r2, y_test, width = barWidth, color = cmap[1], label = labels[1])
axes[2].set_xlabel('Race')
axes[2].set_xticks([r + barWidth for r in range(len(y_train))])
axes[2].set_xticklabels(['White', 'Black', 'Other'])

f.savefig('age_distributions.svg', dpi = 150, bbox_inches = 'tight', pad_inches = 0)


# ## Export

# In[30]:


df_out.to_csv(os.path.join(os.environ['MODELDIR'], 'df_pheno.csv'))

